该平台允许用户在同一个页面集中搜索出不同来源、不同类型的内容，提升用户的检索效率和搜索体验。当有多个项目的数据需要被搜索时，无需针对每个项目单独开发搜索功能，可以直接将数据接入搜索平台，提升开发效率。它的业务逻辑简而言之就是先得到各种不同分类的数据，然后提供一个搜索页面用来支持单一搜索和聚合搜索，还做了一些优化，比如关键词高亮、搜索建议、防抖节流等。
后端技术选择：语言是Java，框架用了SpringBoot；还用了Dubbo（一个轻量级的Java服务框架，用于构建基于RPC的微服务架构）框架去开发RPC（远程过程调用）。微服务平台用到了Nacos，还有微服务网关Spring Cloud Gateway。

后端技术选择：框架是Spring Boot、数据库是MySQL、数据处理用了Elastic Stack技术栈：包括Elasticsearch搜索引擎、Logstash 数据管道和Kibana数据可视化。数据抓取有离线和实时抓取，这里用到了Jsoup和 HttpClient库。数据同步有定时、双写、Logstash、Canal。最后还用到了JMeter 压力测试。

后端开发：
1.	首先是数据库的设计：用发表的文章作为搜索内容，创建文章表，其字段包括标题、内容、标签列表、点赞数、收藏数、用户id、创建时间、更新时间。
2.	然后是从网上爬一些基础文章数据，然后把获取到的文章存入数据库（这个是当时从一个网站上爬的https://www.code-nav.cn/learn/passage）。然后文案内容用离线抓取（也就是只抓一次）存到我自己的数据库，图片就直接从网上的网站上实时抓取，就是用户搜索的时候直接从网上的网站获取，然后抓图片这里用到了Jsoup库，它是为了将获取到的图片信息存入HTML文档，然后从中解析出需要的字段（具体操作：导入Jsoup依赖，根据官方文档导入示例代码，新建picture类然后将获取到的数据封装到picture类中）。
3.	上述数据抓取的代码在service层，然后在controller层中编写聚合搜索接口，前端就可以调用接口用来搜索了。
4.	为了让前端又能一次搜出所有数据、又能够分别获取某一类数据，这里在表中新增一个type字段，并且在controller层中把各个type的接口分别封装到一个文件中，这个type就规定了搜索的一个类型，前端传来的type合法，就在controller层调用相应的接口。但是当type的数量增加到一定程度后，持续的在controller新增文件太过繁琐，所以为了让搜索系统更轻松地接入更多的数据源，这里使用设计模式来解决。首先是门面模式，就是前端不用关心后端从哪里、怎么去取不同来源、怎么去聚合不同来源的数据，更方便地获取到内容（具体实现为：在controller层定义一个统一的接口，来访问所有的type的接口）。然后是适配器模式，就是定制统一的数据源接入规范（什么数据源允许接入?你的数据源接入时要满足什么要求?·需要接入方注意什么事情?）这个系统要求:任何接入我们系统的数据，它必须要能够根据关键词搜索、并且支持分页搜索。这里通过声明接口的方式来定义规范。
5.	Elastic Stack技术栈：随然之前的步骤搜索接口已经编写完成，但现在的搜索还是不够灵活，因为如果搜索一句话的部分词，嗯......就比如说...就比如说，现在有一个词条是“郭昌鑫今天面试”，但用户只搜索了“郭昌鑫面试”，那么就会搜不出来这个词条，这个是因为MySQL的like语句是包含查询的，也就是说我们要搜“郭昌鑫”或者“面试”才可以。所以为了优化搜索，这里使用Elastic Stack，他提供了分词器和倒排索引，将搜索内容按一定规则分词后，按搜索内容作为索引而不是页码作为索引查找文章（具体步骤：首先安装Elastic Stack和组件Kibana，下载Elastic Stack的插件IK分词器，然后选择分词方法，比如智能分词也就是尽量选择最像一个词的拆分方式或者尽可能多地分词）。然后是根据SpringDataElasticsearch的官方文档引入用Spring操作ES的方法。再然后就可以建立ES mapping表了，这里设置两个分词器，分别是analyzer(是在存储时生效的分词器)，用ik_max_word，拆的更碎、索引更多，更有可能被搜出来；另一个是search_analyzer(查询时生效的分词器)，用ik_smart，更偏向于用户想搜的分词。然后用Spring默认提供的操作ES的客户端对象ElasticsearchRestTemplate，它提供了增删改查，返回结果比较完整，但需要自己解析。
6.	查询语言DSL：编写DSL查询语句，然后再将其翻译成Java。查询的逻辑是，先判断查询条件，是必须包含所有标签还是包含任何一个标签即可。然后选择按关键词检索、按标题检索、按内容检索的顺序，最后分页展示所有查询结果。
7.	数据同步：一般情况下，如果做查询搜索功能，使用ES来模糊搜索，但是数据是存放在数据库MySQL里的，所以说我们需要把MySQL中的数据和ES进行同步，保证数据一致，但以MySQL为主。首次安装完ES，就要把 MySQL数据全量同步到ES里。对于全量同步和增量同步，这里有4种同步方式∶第一个是定时任务，比如1分钟1次，找到MySQL中过去几分钟内发生改变的数据，然后更新到ES。它的优点是简单易懂、占用资源少、不用引入第三方中间件，但缺点是有时间差。第二种是双写，即写数据的时候，必须也去写ES，更新删除数据库同理。第三种是用Logstash 数据同步管道（一般要配合 kafka消息队列+beats采集器)。然后第四种是用Canal 监听 MySQL Binlog，实时同步。
8.	然后我用了Logstash，主要就是根据官方文档配置和运行，大致过程就是先监听UDP并输出，然后把MySQL同步给Elasticsearch。
9.	之后还用了Chnal，它是一种订阅数据库流水的同步方式，它是实时同步的，所以实时性很强。它的原理是数据库每次修改时，会修改binlog文件，只要监听该文件的修改，就能第一时间得到消息并处理。Canal就是用来监听binlog并解析为我们可以理解的内容的。这个也是跟着官方文档来做就好。
10.	最后我用了压力测试用来测试平台的稳定性，首先下载Jmeter并启动，然后添加并配置线程组、添加请求头、配置请求头信息，并保存，配置 HTTP 请求，设置断言、设置监听器、查看结果树、查看聚合报告，结果是99%的用户都在响应时间内。
11.	最后还根据Elasticsear的官方文档添加了搜索建议和搜索高亮的功能。
